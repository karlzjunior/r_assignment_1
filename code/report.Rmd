---
title: "Bike Sharing"
author: "Aga, Karla, Nisse, Ole"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: united
    number_sections: false
    toc: true
    toc_float:
      collapsed: true
    df_print: paged
bibliography: references.bib  
---

# Abstract
![](../images/bike_sharing.jpeg)  

"*Bikesharing contributes to the advent of more sustainable transportation in cities around the globe.*" [@beland]. Bikesharing programs are designed to provide short-term bicycle rental in stations dispersed throughout the cities and located near public transportation hubs [@beland]. They have numerous environmental and health benefits, such as reducing congestion, complementing other forms of public transportation and encouraging exercise [@beland]. Additionally, accessible bike rental has a lower barrier of entry than purchasing your own bike and is more convenient for out-of-town commuters.  
In principle bicycles pose a good substitute for car use in urban areas, however, they have certain limitations. Among them is the exposure of cyclists to weather while commuting compared to other means of transportation. It would be intuitive for the number of bike rentals to be dependent on current weather conditions. If that is the case, the extent of that relationship would be important information for the bikesharing companies. Potentially, the information could be a factor in variety if business decisions, including level of pricing or supply for bikes in different seasons.   

---

Considering these possible applications, this report will attempt to answer: **To what extent can weather data predict the number of bike rentals in different parts of the day?** Weather data will includes temperature, wind speed, occurrence of weather phenomena (including storms, snow and rain), 

Operationalization of the RQ:  

* Control variables â€“ possibly a table with all of the variables.  

* Drawing of the path model.  

* Methodology.  

* Data description.  

To describe our data, we retrieved the hourly count of bike rentals between the years 2022 and 2012 from the machine learning repository UC Irvine. The metadata of this dataset belongs to Capital Bikeshare in Washington DC, United States. Thus, focusing on an American population with the corresponding weather and seasonal information.  


# References

<div id="refs"></div>

# Load data

Data set is acquired from a [machine-learning repository](https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset), which provided us with three files, namely:  

* `hour.csv`, hourly data of bike rentals.
* `day.csv`, daily data of bike rentals.
* `README.txt`, providing additional metadata about the file and their data.

We first specify our dependencies and read the data from `hour.csv`. We also load `day.csv`, solely for comparison purposes in our [EDA](#eda) phase.  

```{r import, message = FALSE}
library(tidyverse)
library(fastDummies)
library(kableExtra)
library(gridExtra, exclude="combine")
library(lubridate)
library(car)
library(ICC)
```

```{r read bike}
# Source hourly data for model
source_data <- read.csv("../data/hour.csv", header = TRUE, sep = ",") %>%
  as_tibble()

# Extra daily data for EDA
day_df <- read.csv("../data/hour.csv", header = TRUE, sep = ",") %>%
  as_tibble()

# Clone source
data <- source_data

head(data)
```

We then create a sub-selection of variables that are of interest for our model; these are the control, predictor and outcome variables + variables necessary for EDA and preprocessing.

```{r select}
data <- select(data,
               dteday,
               hr, 
               weathersit, 
               temp, 
               atemp, 
               hum, 
               windspeed, 
               cnt)
```

TODO: perhaps describe columns, # of rows or the like. summarising dataframe?

# Preprocessing & EDA {#eda}

## Data Cleaning {.tabset}

### Expand `dteday` data

Expand `dteday` data by adding `dt_num` (numeric version of day, day_id so to speak).

```{r expand date}
# Converts datetime string to numeric with origin offset.
date_to_num <- function(date, offset) {
   as.integer(as.Date(date, "%Y-%m-%d")) - offset
}

# Fetch origin.
dt_offset <- source_data$dteday[1] %>%
  date_to_num(0) - 1


data <- data %>%
  mutate(
    dt_num = date_to_num(dteday, dt_offset)
  )

# Global variable for amount of unique days.
n_days <- n_distinct(data$dteday)
```

### Clustering of `hr` categories

Create clusters for `hr`  called `hr_seg`. 24 dummy codes it too much. Can use `ICC`, but requires systematic approach and might result in non-continuous clusters (as in not a single range of hours, e.g. 2, 7, 8).

Instead divide based on relation to outcome variable.
```{r hour cut}
# Shift the `hr` data by 2 and increment the hour 23 for easier binning via the cut function.
data <- data %>%
  mutate(hr_idx = hr + 2)

data$hr_idx[data$hr == 23] <- 1

# Cut the 24 hour entries in 3 categories.
data <- data %>%
  mutate(hr_seg = cut(
    hr_idx,
    breaks = c(0, 8, 16, 24),
    labels = c("night", "morning-noon", "eve")
  ))
```

Check whether segmenting of `hr` is applied correctly by looking at single day data.

```{r bin check}
# Check output for single day.
data %>%
  filter(dteday == "2011-01-01") %>%
  arrange(hr) %>%
  select(hr, hr_seg) %>%
  head(24)
```

Segments were chosen based on `hr~cnt` data. Segments needed to be of equal size.

```{r determine segment, message=FALSE}
# Create a `mode` function for aggregation.
mode <- function(x) {
    which.max(table(x))
}

# Plot hr~cnt with current segmentation indicator.
data %>%
  group_by(hr, hr_seg) %>%
  summarise(
    cnt = sum(cnt)
  ) %>%
  ggplot(aes(hr, cnt, fill = hr_seg)) +
    geom_bar(stat = "identity")
```

## Summary/stats?

Summary of our data.

```{r summary}
summary(data)
```

Data contains `r n_days` unique days, meaning that the entirety of 2011 (365 days) and 2012 (366 days) was recorded.

## Distributions {#dists}

Distributions of variables.

```{r distributions, echo=FALSE, message=FALSE}
grid.arrange(
    ggplot(data, aes(hr)) + geom_histogram(binwidth = 1),
    ggplot(data, aes(weathersit)) + geom_histogram(binwidth = 1),
    ggplot(data, aes(temp)) + geom_histogram(),
    ggplot(data, aes(atemp)) + geom_histogram(),
    ggplot(data, aes(hum)) + geom_histogram(),
    ggplot(data, aes(windspeed)) + geom_histogram(),
    ggplot(data, aes(cnt)) + geom_histogram()
)
```

Notice the following:

-   Missing records in some `hr` categories.
-   Occurrence gap in `windspeed` distribution.
-   Category 4 of `weathersit` is barely present. (categorical outlier)

## Outliers {.tabset}

Outlier detection using quantiles.  
```{r outliers, echo=FALSE, message=FALSE}
grid.arrange(
    ggplot(data, aes(temp)) + geom_boxplot(),
    ggplot(data, aes(atemp)) + geom_boxplot(),
    ggplot(data, aes(hum)) + geom_boxplot(),
    ggplot(data, aes(windspeed)) + geom_boxplot(),
    ggplot(data, aes(cnt)) + geom_boxplot()
)
```

Notice the following:

-   Large amount of outliers in `cnt` (outcome variables (due to right-skewed distr).
-   Some outliers in `windspeed`.
-   3x `0.00` values of `hum`.

### Rental count outliers
Large amount of `cnt` outliers is due to low rental count during the night, which shifts the median to a lower value. `hr_seg` acts as moderator, so better to check data displays *per* `hr_seg` cluster.  

```{r cnt outliers, echo=FALSE, message=FALSE}
ggplot(data, aes(cnt, colour = hr_seg)) + geom_boxplot()

ggplot(data, aes(cnt)) + geom_histogram() + facet_wrap(vars(hr_seg))
```

Even then we see that distributions per `hr_seq` are heavily right-skewed, explaining the multitude of outliers.  
Looking at the tail-end of the `cnt` values, these seem to be non-error outliers. Furthermore they seem to be reasonable values due to right-skewness, hence we don't remove them.

### Windspeed outliers

Again right-skewed, hence large values are seen as outliers. Do notice how there's gap between 0 values and the first non-zero values, specifically:  
```{r windspeed outliers}
data %>%
  group_by(windspeed) %>%
  summarise(n = n()) %>%
  arrange(windspeed) %>%
  head()
```

Might be due to sensor threshold for measuring windspeed. In any case, these values fall within the distribution, it is only odd that there's a small increment between the `0.00` occurences and the values thereafter (e.g. `0.0869`).
These might also be possible missing values which are replaced with `0.00`.  
In any case, we cannot know for certain. Since the number of occurrences for `0.00` is in line with neigbouring values, we choose to keep them.

### Humidity outliers

`hum` is left-skewed.
```{r hum outliers}
data %>%
  group_by(hum) %>%
  summarise(n = n()) %>%
  arrange(hum) %>%
  head()
```

## Missing data

Check standard NA values. There are none.

```{r missing standard}
anyNA(data)
```

### Missing records for hour

Some `hr` values seem to have a lower amount of occurrences than others, as can be seen in distribution plot of [Distributions](#dists)

```{r hr missing}
# Count the amount of records per hour.
# Also add a column for amount of *missing* records.
hr_df <- data %>%
  group_by(hr) %>%
  summarise(
    n = n(),
    n_missing_days = n_days - n) # using global variable `n_days`.

ggplot(hr_df, aes(hr, n_missing_days)) +
  geom_bar(stat = "identity")
```

Determine where missing records are located. Seems that a system outtage (or the like) was present on `2012-10-29` and `2012-10-30`, with a combined total of `35` missing records.
```{r missing location, message = FALSE}
# Create dataframe with amount of missing records per day.
missing_df <- data %>%
  group_by(dteday, dt_num) %>%
  summarise(
    n_records = n(),
    n_missing_records = 24 - n_records
  ) %>%
  filter(n_missing_records > 0) %>%
  arrange(desc(n_missing_records)) %>%
  select(dteday, n_missing_records)

head(missing_df, 10)
```

`n_missing_records` is the amount of missing entries on that particalur day.

## Covariance {.tabset}

### Covariance with predictor `atemp`

Have suspicion that `atemp` might be correlated with `temp`, `windspeed` and `hum`, since it is a combined variable of the three (mayhaps). Justify this:

```{r atemp covar, echo=FALSE}
grid.arrange(
  ggplot(data, aes(temp, atemp)) + geom_point(),
  ggplot(data, aes(windspeed, atemp)) + geom_point(),
  ggplot(data, aes(hum, atemp)) + geom_point(),
  nrow = 1
)
```

Can conclude that predictor variables `atemp` and `temp` are highly correlated, whilst `hum` and `windspeed` have a weaker relation with `atemp`.

TODO reason why not to include `atemp` in model comparison.

### Covariance with outcome variable `cnt`

Create covariance table of predictor vs outcome variables.
```{r cnt covar table}
covar_df <- data.frame(
  temp = cor(data$cnt, data$temp),
  hum = cor(data$cnt, data$hum),
  windspeed = cor(data$cnt, data$windspeed),
  weathersit = cor(data$cnt, data$weathersit)
)

covar_df
```

Remark:  

- Non-linear relation between `hum` and `cnt`
- Negative relation between `windspeed` and `cnt`
- Positive relation between `temp` and `cnt`, up until high temperatures are reached (ppl dont like biking in hot water, don't blame them).

```{r cnt covar scatter, echo=FALSE, message=FALSE}
plot_cnt_covar <- function(plot) {
  plot + 
    geom_point() +
    geom_smooth(method = 'loess') +
    facet_wrap(vars(hr_seg))
}

ggplot(data, aes(temp, cnt)) %>% plot_cnt_covar()
ggplot(data, aes(windspeed, cnt)) %>% plot_cnt_covar()
ggplot(data, aes(hum, cnt)) %>% plot_cnt_covar()
```

## Data Aggregation
After having created `hr_seq`, we aggregate the data based on both the date (`dteday`) and the hour segments (`hr_seg`. In case of dichotomous variables, we take the `mode` of the variable, with earlier defined function.
```{r aggregate hour, message=FALSE}
# Aggregate over `hr_bin` factor.
data <- data %>%
    group_by(dteday, hr_seg) %>%
    summarize(
        temp = mean(temp),
        atemp = mean(atemp),
        hum = mean(hum),
        windspeed = mean(atemp),
        weathersit = mode(weathersit),
        cnt = sum(cnt)
    )
```



# Model creation & comparison

Later on in [Assumptions](#assum) we concluded a non-linear (higher-order) relation between `hum` and `cnt`. To approximate a linear relation, we have transformed the data to `f(x) = x^3`, saved in column `hum3`.  

```{r solve non lin}
data$hum3 = data$hum^3
```

Create simple and complex models. Order is based on covariance table (high to low).
```{r model creation}
# Create models.
model1        <- lm(cnt ~ temp, data)
model2        <- lm(cnt ~ temp + hum3, data)
model3        <- lm(cnt ~ temp + hum3 + weathersit, data)
model4        <- lm(cnt ~ temp + hum3 + weathersit + windspeed, data)

# Include moderator for model of choice (#2), for comparison analysis.
model2_mod    <- lm(cnt ~ (temp + hum3)* hr_seg, data)
```

Comparison results table.
```{r comparison}
RMSE <- function(model) {
  model$residuals^2 %>% mean()
}

comp_df <- data.frame(
  model = c('model1', 'model2', 'model3', 'model4', 'model2_mod'),
  predictors = c('temp', 'temp + hum3', 'temp + hum3 + weathersit', 'temp + hum3 + weathersit + windspeed', 'temp + hum3'),
  moderator = c('', '', '', '', 'hr_seg'),
  AIC = c(AIC(model1), AIC(model2), AIC(model3), AIC(model4), AIC(model2_mod)),
  BIC = c(BIC(model1), BIC(model2), BIC(model3), BIC(model4), BIC(model2_mod)),
  RMSE = c(RMSE(model1), RMSE(model2), RMSE(model3), RMSE(model4), RMSE(model2_mod))
)


comp_df
```

Anova tests.
```{r anovas}
# Simple and complex model
anova(model1, model2)
anova(model2, model3)
anova(model3, model4)

# Test addition of moderator
anova(model2, model2_mod)
```
## Interpration


# Assumptions {#assum}

## Linearity {.tabset}

Small remark, the `car` library with `crPlots` function is not applicable on model with interactions, hence we plot per predictor to check relations.

### `temp`

```{r lin temp, message=FALSE, echo=FALSE}
ggplot(data, aes(temp, cnt, colour = hr_seg)) +
  geom_point() +
  geom_smooth()
```

The relationship is not quite linear. It seems that, when the temperature gets too high, people stop renting bikes. The higher temperatures which stop people from renting bikes, do not seem to occur in the night. Therefore, the relationship between temperature and rent count seems linear in the night.

### `hum`

```{r lin hum, message=FALSE, echo=FALSE}
ggplot(data, aes(hum, cnt, colour = hr_seg)) +
  geom_point() +
  geom_smooth()
```

To combat this non-linearity issue, we have transformed the predictor variable `hum` (as mentioned earlier). This does make the interpretation of the model less intuitive.

```{r lin hum3, message=FALSE, echo=FALSE}
ggplot(data, aes(hum3, cnt, colour = hr_seg)) +
  geom_point() +
  geom_smooth()
```

This is the best transformation we could come up with. It's not perfect, but we're accepting this as sufficiently linear.

## Full rank predictor matrix


The dataset contains 2190 observations (that is, the dataset after aggregating the data). It only contains 9 variables, including the transformed humidity variable. There are definitely more observations than there are variables.

Next, we need to know whether there is a relationship between the two predictors we are using, temperature and humidity.

```{r multicol, message=FALSE, echo=FALSE}
ggplot(data, aes(temp, hum3)) +
  geom_point() +
  geom_smooth()
```

This graph shows there is no relationship between temperature and humidity, so we can conclude there is no issue of multicollinearity.

## Exogenous predictors


We need to check whether there is no relationship between the predictors of the model, and its errors. 

```{r cov e}
cov_res <- cov(predict(model2_mod), resid(model2_mod))
cov_res
```

This value is practically equal to zero.

Next, we need to know whether the mean of the errors of the model are equal to zero.

```{r pred res relation, message=FALSE, echo=FALSE}
grid.arrange(
  ggplot(data, aes(temp, resid(model2_mod))) +  geom_point() +  geom_smooth(),
  ggplot(data, aes(hum, resid(model2_mod))) +  geom_point() +  geom_smooth()
)
```

The first graph is not quite right, though the line only starts deviating from 0, in the latter part of the graph. There's less data points there as well, so it makes sense. We can make do, though.
The second graph is completely fine.

## Constant & finite variance


We need to find out whether the variance of the errors is constant over all levels of the predictor (homoscedasticity). That is shown in the first plot below.
The second plot is similar, but it shows standardized residuals (or, more accurately, their square root).

```{r homosced}
# Residual plot.
model2_mod %>% plot(1)
model2_mod %>% plot(3)
```

The first plot is fine: the red line should be y = 0. That seems to be fine.
The second plot also seems to be roughly fine. There is a weird cluster of errors in the first part of both graphs; those are responsible for the "night" rentals.

## Independent errors


The errors should be independent. Now, we can check for clustering, though we have already manually clustered the data. We can check if that clustering was sufficient.

```{r}
ICCbare(data$temp, resid(model2_mod))
ICCbare(data$hum, resid(model2_mod))
ICCbare(data$hr_seg, resid(model2_mod))
```

All ICC are close enough to 0 to conclude that there is no issue of dependence of errors.

## Normally distributed errors


The errors should be normally distributed. We can make a Q-Q plot to check whether that's true.

```{r qqplot}
plot(model2_mod, 2)
```

We want the errors to be as close to the dotted line as possible. It's not looking to great, but it's okay enough.

## Influential data points


We need to check whether the model contains any influential data points. That includes outliers and high-leverage observations. We can check the outliers first.

```{r indep res}
plot(rstudent(model2_mod)) 
```

Again, the errors should be close to y = 0. And again, it doesn't look to great, but most of the errors seem to be close to y = 0. Interestingly, the earlier outlying values seem to be below 0, while the later values seem to be above 0. It may be possible that the bike renting program started at the first day of this dataset, so it became more popular over time. There is no way to be sure, though.

Next, we need to measure Cook's distance. Outliers are included in this measure as well, but since we checked those already, we really want to know about the high-leverage points.

```{r outliers post model}
plot(cooks.distance(model2_mod))            # Seems bad, but look at scale
plot(dfbetas(model2_mod)[,1])               # Seems good
```

Nowhere, Cook's distance is high at all. So this assumption seems to be sufficiently met.



# Interpretation of key results

## Model statistics and coefficients

In this section, we will check the quality of our linear model using the R function `summary()` for "model 2" and "model 2 mod" for evaluating the accuracy of our regression model when considering the coefficients and statistics results in R. We will add a new categorical variable named `hr_seg` as a moderator, counting the hours for the `morning-noon` and `eve` (evenning) groups of the day.

```{r}
# Regression line model: check statistics and coefficients 
summary(model2)
```

The summary outputs shows 6 components, including:
* *Call:* Shows the function call to compute our regression model, which is:
$$
lm(formula = cnt ~ (temp + hum3) * hr_seg, data = data)
$$
* *Residuals:* A quick view of the distribution of the residuals, which by definition have a mean zero. 
* *Coefficients:* Shows the regression beta coefficients and their statistical significance. Predictor variables, that are significantly associated with the outcome variable, appear marked by stars.
* *Residual Standard Error*, *R-squared*, and the *F-statistic* check our model performance.

## Multiple Linear Regression

## Partial effects

This part of the analysis examines the partial effects of the predictors using model 2, since it is crucial to controlling confounds and adequately modeling real-world phenomena.

### Interpretting regression coefficients

### What is the effect of hummidity on the average of total rental bikes, after controlling for temperature?
First, the intercept tells us the location of the dependent variable when the independent variable equals 0 ($x = 0$). 
* Using "model 2" as an example, the expected average bike rental when temperature reaches 0Â°C is 659.44 units.

Second, the regression coefficients for model 2 indicate the amount of change in the predicted variable when the predictor variable is changed with one unit. 
* For this example, this means that for each Celcius degree increase, average rental bike is expected to increase by 2974.36 units, after controlling for hummidity ("hum3"). 
* Meanwhile, for each additional point of hummidity, average bike rental is expected to decrease by 2082.68 units, after controlling for temperature.

### Significance testing - P values

Probability values measures the strengthens evidence of the null hypothesis with a fraction or decimal value between 0 and 1. If the result is closer to 0, then the stronger the evidence against the null hypothesis. 

Viewing the `summary` results of "model 2", the predictor variables results obtained that `p < 2.2e-16`. Thus, rejecting the null hypothesis. Our conclusion explains there is a statistical significant or strong relationship between the predictor variables and the response variables due to a smaller p-value. 



# Moderator variables

## Categorical predictors

```{r}
# Categorical variables: Check coefficients and statistics results 
summary(model2_mod)
```

Reminder: the appearance of the categorical variable `hr_seg` divides the count of hours into the following categories...
* morning-noon. 
* eve (standing for evenning time). 

## Interpretting categorical coefficients

In the output, we see that the categorical variable `hr_seg` is added to our multiple linear regression model by testing the relationship between bike rental and temperature to determine its statistical relationship. 

Comparing and contrasting the results between the multiple linear regression model and this categorical predictor, we note the following changes: 

*Temperature and hummidity*
* In comparison to the multiple linear regression model, temperature remains having an average positive estimation of 587.58 bike rental units while hummidity remains showcasing a decreased average estimation of 94.16 bike rental units.

*Intercept and reference group*
* `Hr_seg` represents a segment of the day in hours and is categorized as the reference group of this model. 
* The Intercept represents the average bike rental for a bike rented within a segment of the day (`hr_seg`), assuming all other variables are held constant. 

*Categorical coefficients* 
* The average estimated value for renting a bike during the morning-noon segment of the day is about 961.65, being higher in comparison to renting a bike in the evenning of the day, which totals to 548.62 units.
* After controlling temperature, the average estimated bike rental during the morning-noon is about 1627.07, whereas the average estimated bike rental during the evening is 3076.57. Around 1449.5 increased units, meaning that is more fequent on average to rent a bike during the evening, when temperature is controlled. 
* In comparison to hummidity, both categorical coefficients are decreased, with an average estimated bike rental of -848.74 during the morning-noon, and an average estimated bike rental of -1149.92 during the evenning. 

### Model Fit
How much variation in bike rental is explained by the two models?

## Comparison of summary statistics and coefficients
Comparing and contrasting the results in both models (multiple regression line and categorical predictors), temperature and humidity remain having the same relationships for their average estimated values. Temperature is increased, while humidity is decreased. 

For the highest estimated value, the second model indicates an average bike rental during the segment of the evenning with 3076.57 units, after controlling for temperature. Even higher than the values in the multiple linear regression model.

In the second model, hummidity is the only variable which does not necessarily have an statistical relationship with bike rental, showing a p > 0.372. Certainly, way higher than the first model.

## Model accuracy


## Cross-validation of results


